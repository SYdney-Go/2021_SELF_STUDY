{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 머신러닝이란?\n",
    "- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\n",
    "- 작업 T에 대한 프로그램의 성능 P를 E로 학습하여 성능을 향상하는 과정\n",
    "    - 스팸 메일의 분류 (T)\n",
    "    - 훈련 세트 (E)\n",
    "    - 훈련 사례 (샘플) (E)\n",
    "    - 훈련 데이터 (E)\n",
    "    - 정확도 (P)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 왜 머신러닝을 사용하는가?\n",
    "* 전통적인 방식 : 사람이 패턴대로 알고리즘 작성 → 문제가 어려우면 규칙이 점점 길고 복잡 → 유지 보수의 어려움\n",
    "* 머신러닝 방식 : 컴퓨터가 패턴을 감지하여 자동으로 학습 → 프로그램이 짧고 유지 보수가 쉬움 + 정확도도 더 높음\n",
    "    * 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제를 해결\n",
    "    * 데이터 마이닝 : 복잡한 데이터에서 보이지 않는 패턴을 새로 발견"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 어플리케이션 사례"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4 머신러닝 시스템의 종류\n",
    "## 1. 학습하는 동안의 감독 형태나 정보량에 따른 분류\n",
    "### (1) 지도 학습\n",
    "- 훈련데이터에 레이블이 존재\n",
    "- 분류, 회귀\n",
    "- 종류 : k-최근접 이웃, 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신, 결정트리, 랜덤 포레스트, 신경망\n",
    "\n",
    "### (2) 비지도 학습\n",
    "- 훈련데이터에 레이블이 없음\n",
    "    - 군집\n",
    "        - 비슷한 그룹으로 자동으로 묶어주기!\n",
    "        - 종류  : 계층 군집 분석(HCA), 이상치 탐지, 특이치 탐지, 원-클래스 , 아이솔레이션 포레스트\n",
    "    - 시각화와 차원 축소\n",
    "        - 시각화 : 레이블이 없는 고차원 데이터를 넣어서 도식화한 표현들을 확인 -> 이때 구조가 유지되므로 데이터의 조직을 이해하는데 도움이 된다. 또 새로운 패턴을 발견할 수도 있다.\n",
    "        - 차원축소 : 정보를 너무 많이 잃지 않으면서 데이터를 간소화하는 방법 -> 상관관계가 있는 여러 특성 합치기 (특성 추출)\n",
    "        - 종류 : 주성분 분석(PCA), 커널 PCA, 지역적 선형 임베딩(LLE), t-SNE\n",
    "    - 연관 규칙 학습\n",
    "        - 데이터간의 흥미로운 관계를 찾기\n",
    "        - 종류 : 어프라이어리, 이클렛\n",
    "\n",
    "### (3) 준지도 학습\n",
    "- 일부만 레이블이 있는 데이터를 다루는 경우\n",
    "- 지도학습 + 비지도 학습\n",
    "- 예시 : 비지도 - 제한된 볼츠만 머신(RBM) -> 지도 - 심층 신뢰 신경망 (DBN)\n",
    "\n",
    "### (4) 강화 학습\n",
    "- 에이전트 : 학습하는 시스템\n",
    "- 환경을 관찰 -> 행동을 실행 -> 보상 획득 or 벌점 => 정책(최상의 전략) 학습\n",
    "\n",
    "## 2. 배치 학습과 온라인 학습\n",
    "### (1) 배치 학습\n",
    "- 점진적인 학습 불가능 -> 데이터를 전부 사용하여 훈련\n",
    "- 시간과 자원 소모 많음 -> 오프라인에서 수행 (오프라인 학습)\n",
    "- 새로운 데이터를 학습하려면 전부 처음부터 다시 학습 -> 학습 ㅅ간과 자원이 많이 든다...\n",
    "\n",
    "### (2) 온라인 학습\n",
    "- 데이터를 순차적으로 또는 미니 배치로 훈련\n",
    "- 장점\n",
    "    - 학습 단계가 빠르고 비용이 적게 들어서 즉시 학습이 가능\n",
    "    - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템, 컴퓨팅 자원이 제한된 경우 좋다!\n",
    "    - 학습이 끝난 데이터를 더 보관할 필요가 없다!\n",
    "    - 외부 메모리 학습 : 아주 큰 데이터에 사용 가능 -> 일부 데이터를 읽고 학습하는 과정을 바복\n",
    "- 학습률\n",
    "    - 학습률이 높다 = 시스템이 데이터에 빠르게 적응, 이전 데이터를 빠르게 잊ㅈ어버림\n",
    "    - 학습률이 낮다 = 시스템의 관성 증가로 학습 속도가 느려짐, 새 데이터의 노이즈나 대표성 없는 데이터 포인트에 덜 민감\n",
    "- 단점\n",
    "    - 시스템이 나쁜 데이터가 주입된 경우 -> 시스템 성능의 즉각적인 점진적 감소\n",
    "\n",
    "## 3. 사례 기반 학습과 모델 기반 학습\n",
    "### (1) 사례 기반 학습\n",
    "- 훈련 데이터를 단순히 기억하고 있기 -> 유사도를 측정하여 분류하기\n",
    "\n",
    "### (2) 모델 기반 학습\n",
    "- 샘플들의 모델을 만들어 예측이 사용하기\n",
    "- ① 모델 선택(예, 선형모델)\n",
    "- ② 모델의 파라미터를 조정하기(모델이 얼마나 좋은지[효용함수, 적합도 함수] 나쁜지 판단[비용함수]). 이를 모델을 훈련시킨다고 한다\n",
    "- ③ 결과 시각화하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### 예제 1-1. 사이킷런을 활용한 선형 모델의 훈련과 실행\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "oecd_bli = pd.read_cvs('데이터 어디서 뭘 가지고 온거임...ㅠ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.5 머신러닝의 주요 도전 과제\n",
    "\n",
    "## (1) 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "## (2) 대표성 없는 훈련 데이터\n",
    "\n",
    "- 샘플링 잡음 : 샘플이 작은 경우 우연에 의해 대표성이 없는 데이터가 생길 수 있다.\n",
    "- 샘플링 편향 : 잘못된 표본 추출로 인한 대표성을 띄지 못하는 경우\n",
    "\n",
    "## (3) 낮은 품질의 데이터\n",
    "\n",
    "- 이상치\n",
    "- 일부 샘플의 특성이 빠져있는 경우\n",
    "\n",
    "## (4) 관련 없는 특성\n",
    "\n",
    "- 특성 공학 : 훈련데이터와 관련이 있는 좋은 특성들을 찾는 것\n",
    "    - 특성 선택 : 가지고 있는 특성 중 훈련에 가장 유용한 특성을 선택하기\n",
    "    - 특성 추출 : 특성을 결합하여 더 유용한 특성을 만들기 (차원특성 알고리즘같은것)\n",
    "\n",
    "- 새 데이터를 수집하여 새 특성을 만들기\n",
    "\n",
    "## (5) 훈련 데이터 과대적합\n",
    "- 과대적합 : 훈련데이터에는 잘 맞지만, 일반성이 너무 떨어지는 것\n",
    "- 해결방법\n",
    "    - 규제 : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위한 방법\n",
    "    - 모델의 파라미터들의 값을 조절하기 (하이퍼파라미터)\n",
    "\n",
    "## (6) 훈련 데이터 과소적합\n",
    "- 모델이 너무 단순해서 데이터의 내제된 구조를 학습하지 못하는 것\n",
    "- 해결방법\n",
    "    - 모델 파라미터가 더 많은 모델 선택\n",
    "    - 학습 알고리즘에 더 좋은 특성을 제공(특성공학)\n",
    "    - 모델의 제약을 줄이기 (규제 하이퍼파라미터의 감소)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.6 테스트와 검증\n",
    "\n",
    "- 모델이 새로운 샘플에 얼마나 잘 일반회 될지 어떻게 알 수 있을까?\n",
    "\n",
    "- 실제 서비스에 때려넣기...ㅋㅋㅋㅋㅋㅋㅋ\n",
    "\n",
    "- 훈련 데이터를 훈련 세트와 테스트 세트로 나눠서 오차에 대한 추정값을 얻어보기\n",
    "\n",
    "## (1) 하이퍼파라미터 튜닝과 모델 선택\n",
    "- 모델 평가 : 테스트 세트를 사용하기 -> 이때 테스트 데이터에서 과적합이 발생할 수 있다!!!\n",
    "- 홀드아웃 검정 : 훈련 세트의 일부를 떼어내어(홀드아웃세트 = 검증세트=개발세트=데브세트) 후보 모델의 평가 -> 이중 가장 좋은 하나를 고르기\n",
    "    - ① 훈련세트에서 검즈세트를 뺀 상태에서 다양한 하이퍼 파라미터 값을 가진 모델들의 훈련 진행\n",
    "    - ②검증 세트에서 가장 좋은 모델을 선택하기\n",
    "    - ③검증세트를 포함한 전체 훈련 세트에서 다시 훈련하여 최종 모델 만들기\n",
    "    - ④최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정하기\n",
    "    - 단점 : 검증세트가 너무 작으면 모델의 평가가 어려움, 검증 세트가 너무 크면 훈련 데이터 세트가 너무 작아진다\n",
    "    - 해결 방법 : 교차 검증의 수행 (검증 세트마다 나머지 데이터에서 훈련한 모델을 평가하여 모든 검증 세트의 성능을 평균하기, 대신 훈련시간은 증가...)\n",
    "\n",
    "## (2) 데이터 불일치\n",
    "- 훈련데이터는 많이 얻었지만 실제 제품의 데이터를 대표하지 못하는 경우\n",
    "- 검증 세트와 테스트 세트에 데이터들이 잘 섞여서 들어가야한다...\n",
    "- 훈련-개발세트 = 모댈을 훈련세트에서 훈련 -> 훈련-개발 세트에서 평가하기"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('jupyter': virtualenv)"
  },
  "interpreter": {
   "hash": "dbc4d67c486c8529ccab8645044d83be214319cefe5619226d22e06c4885e26d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}